---
layout: post
title: GPGPU
categories: []
---

현재 학교에서 졸업프로젝트를 진행하고 있다. 최종적인 목표는 그래픽 카드를 구현하는 것이지만, 현재 공부할 자료가 부족하여 `GPGPU`공부로 대신한다. 다음 내용은 내가 수박 겉핥기나마 공부를 하고 복습하고 기록하는 의미로 쓰는 글이라고 할 수 있다.

### 1. 그래픽 카드가 대충 돌아가는 개념

그래픽 카드의 대충 돌아가는 개념을 이해해야 한다. 그래픽 카드는 하나에 한 개의 명령만을(물론 요즘은 좀 다르지만 그래도) 처리하는 `cpu`와는 달리, 매우 많은 연산 장치를 동시에 가동하기 때문에, 매우 높은 병렬성을 구성할 수 있다. 즉, 아주 세세하고 복잡한 일을 한 번에 한 개씩 처리하는 `cpu`와는 달리, 동일한, 반복적인 작업을 한번에 처리하는 것이라고 생각하면 좋다. 공장에서 많은 사람들이 많은 컨버이어 밸트에서 동일한 작업을 하고 있는 것이라고 생각하면 좋고, 이 공자에서 생산할 제품을 설계하고 있는 한명의 설계자를 `cpu` 에 비유하면 좋을 것이다.

### 2. 그래서 그 많은 작업들을 어떻게 처리할 것인데

`cpu`의 용어들은 많이 알려져 있기 때문에 친숙하지만, `gpu`에서는 컴퓨팅 자체를 새로운 시각으로 바라보기 때문에 처음에 생소한 개념들이 아주 많이 등장한다. 그러나 그 시작은 항상 간단하고 단순한 많은 작업을 어떻게 하면 동시에 처리할 수 있을까이다. 결과적으로 `gpu`는 `cpu`보다 많은 연산을 동시에 처리할 것이기 때문에 연산 자체를 책임지는 `ALU`를 아주 많이 준비한다. `nVidia`에서는 이것을 `SP` 또는 `Streaming Processor`라고 부른다. `nVidia`와 같은 아키텍쳐 설계하는 회사들은 이 많은 `SP`들을 효율적으로 관리하기 위해 이를 한 묶음으로 묶고 이를 `SM` 또는 `Streaming Multiprocessor`라고 불렀다. 옛날에는 한 `SM`에 8개의 `SP`가 포함되었는데, 요즘은 그 수가 더 많이 증가하는 추세이다. 이 `SM`에서는 연산을 처리하기 때문에, 연산의 피연산 값들과 연산 후의 결과를 저장할 메모리가 필요할 것이다. 이를 `SP` 단위로 준비하지 않고, 관리하기 편하도록 `SM` 단위로 제공하고, 모든 `SP`들이 이를 공유하도록 하였다.

### 3. SM 안에 어떤 메모리들이 있는가?

`SM`에는 세 가지 메모리가 존재한다. 첫 번 째는 바로 `cpu`와 비슷하게 `reg`들이다. `gpu`는 매우 많은 연산을 한 번에 처리하기 때문에 `reg`의 개수가 `cpu` 보다 훨씬 많다. 한 `SM`에 `reg`가 2^16, 즉 6만 5천개 정도가 존재한다.

두 번째는 바로 `cache`이다. 한 `SM`마다 `L1 $`가 존재하고, 모든 계산 유닛들이 이를 공유한다.

세 번째는 프로그래머가 직접 사용할 수 있는(뭔가 `heap`같은 느낌) 자유로운 공간인 `shared memory` 또는 `Scratch Pad Ram`이 있다. 이 메모리는 프로그래머가 직접 프로그래밍하여 사용할 수 있도록 디자인 되어 있다.

### 4. `SM`들이 모여...

그래서 이런 `SM`들을 두어개 모으고, 그래픽 연산에 필요한 `Raster Engine`(이것은 추후에 공부하도록 하겠다) 등을 붙여서 `GPC` 또는 `Graphic Processing Cluster`라는 것을 만든다. 그리고 이것들을 모아서 최종적으로 `GPU`를 구성하게 된다.

### 5. 그러면 도대체 프로그래밍과 어떻게 연결되는 것인가...

`CUDA` 프로그래밍을 하게 되면, `gpu`에서 돌릴 프로그램을 다음과 같이 작성하게 된다. `gpu`는 매우 많은 데이터들을 처리하기 때문에, 우선 `cpu`에서 그것을 생성하고, `gpu`의 메모리로 복사를 하게 된다. 그리고 이 데이터들 각각에 적용할 프로그램(즉 한 `SP`에서 돌아갈 프로그램)을 작성하게 된다. 즉 공장에서 많은 사람들이 단순한 반복적인 일을 하기 때문에, 한 사람이 할 일만 정하면, 다른 사람들은 모두 그것을 따라하면 되기 때문이다. 그리고 그것을 몇명의 사람들이 따라 할 것인지를 정하게 된다. 이때 `SM`에 이 작업들을 수월하게 건네주기 위해서 `TB` 또는 `Thread Block`이라는 단위를 우리가 정하게 된다. 이 `Thread Block`에 `thread`를 몇개 넣을지(이를 x, y, z 3차원으로 결정한다. 이는 나중에 더...), 그리고 이 `TB`를 몇개를 만들지를 결정한다. 이것을 `grid`라고 하고, 한 커널 프로그램은 이 `grid`로 이루어져 있다.

### 6. 우리의 프로그램을 받은 GPU가 하는 것...

이렇게 되면, `gpu`에서는 `Thread Block Scheduler`라는 것이 있어서(`nVidia`에서는 `GigaThread Engine`이라는 거창한 이름으로 부른다) 전달받은 `grid`의 `TB`들을 `Round Robin` 방법으로 스케쥴링한다. 즉 순서대로 각 `SM`에 한개의 `TB`씩 넣고 다시 처음으로 돌아와서 다시 한개씩 넣고... 다 찰 떄까지 하는 방식이다. 이때 `TB`는 `SM`가 돌릴 수 있는 최대 `thread` 개수, 최대 `reg` 사이즈, `shared memory` 사이즈를 바탕으로 최대 개수를 할당받는다. 즉 `TB`가 사용하는 `thread`, `reg`, `shared memory`를 기반으로 최대한 우겨넣을 수 있는 `TB`들을 넣게 된다.

### 7. TB들을 전달받은 후 SM이 하는 것

이렇게 전달받은 `TB`에는 수많은 thread들이 존재할 텐데, 이를 32개의 `thread` 단위인 `1 warp`으로 쪼개고, 한 개의 명령어를 이 `warp` 단위를 통해서 수행시키게 된다. 각 `SM`들 안에는 이 `warp scheduler`가 또 존재해서, 이를 처리하게 된다. 이 부분은 공부가 더 필요한 부분이다.
